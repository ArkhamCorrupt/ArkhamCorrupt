{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpgCeG8qsci62+2k7inY5h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArkhamCorrupt/ArkhamCorrupt/blob/main/Tensors_Video_Demos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Tutorial #2"
      ],
      "metadata": {
        "id": "VL3Lt-NLHaOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzOSA6ZXAYUA",
        "outputId": "e28b761a-733b-482c-8932-f1ffdf19de4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.1933e-34, 0.0000e+00, 1.1933e-34])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.empty(3)#like a 1dimensional vector with 3 elements\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.empty(2, 3)#like a 2 dimensional vector with 3 elements\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VewcTClWA1Gv",
        "outputId": "ad1c12d5-db43-423b-e293-4df9be60797c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-5.5765e-21,  4.5598e-41,  1.1969e-34],\n",
            "        [ 0.0000e+00,  4.4842e-44,  0.0000e+00]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.rand(2,2)#creates a random 2 by 2 tensor you can also say torch.ones or torch.zeros to make them ones or zeros\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpxKi1xoBIdN",
        "outputId": "e9a3ff14-f14d-4aff-b825-143f18bb6c5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1592, 0.9078],\n",
            "        [0.1153, 0.3356]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(2,2, dtype=torch.int)\n",
        "print(x.size())#this can take a look at the size of the tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmE_ByfABgZC",
        "outputId": "5074a755-cc1d-4f78-c5a0-9650cd2ef99f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([2.5, 0.1, 5.7 ])#this makes a list\n",
        "print(x)#this prints the list "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27ZI5N9wCALo",
        "outputId": "97ff0378-509b-4f0d-d531-7d92f932422b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5000, 0.1000, 5.7000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.rand(5,3)#makes a 5 dimensional tensor of 3 values\n",
        "print(x)\n",
        "print(x[:,0])#this would be the first column of all the rows\n",
        "print(x[0,:])#this would be the first row of all the columns\n",
        "print(x[1,1])#this would be the second column, second row,second spot\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0K-TbbUDbbO",
        "outputId": "9bf53d9a-1c90-40f9-854c-6d5c34a4fd15"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5005, 0.4796, 0.9684],\n",
            "        [0.1577, 0.2170, 0.0753],\n",
            "        [0.8683, 0.1833, 0.4663],\n",
            "        [0.8609, 0.1278, 0.2586],\n",
            "        [0.0767, 0.7240, 0.7561]])\n",
            "tensor([0.5005, 0.1577, 0.8683, 0.8609, 0.0767])\n",
            "tensor([0.5005, 0.4796, 0.9684])\n",
            "tensor(0.2170)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.rand(4,4)\n",
        "print(x)\n",
        "y = x.view(-1,8)\n",
        "print(y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR-GKkFaEh82",
        "outputId": "a8e2d8f3-42fa-4187-c39b-3d7beb4c37bc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0893, 0.8888, 0.1482, 0.9330],\n",
            "        [0.5225, 0.7813, 0.1180, 0.5014],\n",
            "        [0.5320, 0.1974, 0.7525, 0.1019],\n",
            "        [0.4266, 0.2804, 0.7656, 0.7999]])\n",
            "torch.Size([2, 8])\n",
            "tensor([[0.4310, 0.8562, 0.9322, 0.7497],\n",
            "        [0.2537, 0.8015, 0.6622, 0.7722],\n",
            "        [0.8626, 0.6522, 0.4562, 0.7932],\n",
            "        [0.5100, 0.6554, 0.6188, 0.4404]])\n",
            "torch.Size([2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()#converts a into a numpy array\n",
        "print(b)\n",
        "\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCT_p12nFANN",
        "outputId": "c87f931b-f3be-46ad-93b9-490d4b1ff785"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "a = np.ones(5)\n",
        "print(a)\n",
        "b = torch.from_numpy(a)#converts a numpy array into a tensor\n",
        "print(b)\n",
        "\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpGY2lEHFrVe",
        "outputId": "0e3c5e4f-301c-47e2-ac49-4bc3f0a1439a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "x = torch.ones(5, requires_grad = True)#reminds it that it needs to calculate gradience\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQvyCTogG3UK",
        "outputId": "8f00335e-68d7-44e6-cfac-28db96c34835"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch Tutorial #3: Autograd Gradient Computation"
      ],
      "metadata": {
        "id": "uTFS7fMGHjNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(3, requires_grad = True)#tensor with 3 random values\n",
        "print(x)\n",
        "\n",
        "y = x + 2\n",
        "print(y)\n",
        "z = y*y*2\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "z.backward() #calculates the gradient of z, dz/dx or z in respect to x\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM2qngtAHrjv",
        "outputId": "83047435-4c69-4e28-fc24-435052cee09e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0973,  0.4605, -2.2168], requires_grad=True)\n",
            "tensor([ 2.0973,  2.4605, -0.2168], grad_fn=<AddBackward0>)\n",
            "tensor(6.9999, grad_fn=<MeanBackward0>)\n",
            "tensor([ 2.7965,  3.2807, -0.2891])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "#To stop PyTorch from creating this gradient function use these 3 ways:\n",
        "#x.requires_grad_(False)\n",
        "#x.detach()\n",
        "#with torch.no_grad():\n",
        "\n",
        "x.requires_grad_(False)\n",
        "y= x.detach()\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA3--ane5CkV",
        "outputId": "3ddcf3cb-92b7-4d5f-d070-c3e8fda76cf7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7602, -1.0751,  0.5233], requires_grad=True)\n",
            "tensor([-0.7602, -1.0751,  0.5233])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(4):\n",
        "  model_output = (weights*3).sum()\n",
        "\n",
        "  model_output.backward() #this gives us the gradient\n",
        "\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_()#this puts all the values back at 3 instead of 3,6,9,12 that you would see if you comment out this line\n",
        "  #you could also call that emptying the gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdPy62B_8CaU",
        "outputId": "16ce2376-1951-44ff-d5ad-63affd050586"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.SGD(weights, lr=0.01)  #our lr here is our learning rate\n",
        "optimizer.step()\n",
        "optimizer.zero_grad()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "RRdyQaSw83FX",
        "outputId": "54ee6526-263e-4bc4-9750-29d33d0425e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9f2aa288a9e6>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#our lr here is our learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, lr, momentum, dampening, weight_decay, nesterov, maximize, foreach, differentiable)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Nesterov momentum requires a momentum and zero dampening\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             raise TypeError(\"params argument given to the optimizer should be \"\n\u001b[0m\u001b[1;32m    179\u001b[0m                             \u001b[0;34m\"an iterable of Tensors or dicts, but got \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                             torch.typename(params))\n",
            "\u001b[0;31mTypeError\u001b[0m: params argument given to the optimizer should be an iterable of Tensors or dicts, but got torch.FloatTensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "#whenever we want to calculate the gradience we must specify that it requires grad=True\n",
        "\n",
        "z.backward()\n",
        "weights.grad.zero_()"
      ],
      "metadata": {
        "id": "pUqXvCif9fmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 4: Backpropagation"
      ],
      "metadata": {
        "id": "Jea4iPgX94uZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#backprop has 3 steps:   1.Forward Pass: Compute the loss      2. Compute Local Gradients      3. Backward Pass: Compute dLoss/dWeights using the Chain Rule\n",
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "weight= torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "#Computing the forward pass and computing the loss\n",
        "y_hat = weight * x\n",
        "loss = (y_hat - y)**2\n",
        "\n",
        "print(loss)\n",
        "\n",
        "#backward pass\n",
        "loss.backward()\n",
        "print(weight.grad)\n",
        "\n",
        "#Update the weights\n",
        "#next forward and backwards pass\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD3uJpI1-AD4",
        "outputId": "47a7bc85-eb6e-41d2-ced6-f5dd7d2b045e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 5: Gradient Descent using Autograd"
      ],
      "metadata": {
        "id": "J4olUbj9BUsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# f = w * x\n",
        "\n",
        "# f = 2 * x\n",
        "x = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "##### model prediction ######\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = Mean Squared Error or MSE\n",
        "def loss(y, y_predicted):\n",
        "    return ((y - y_predicted) ** 2).mean()\n",
        "\n",
        "# gradient\n",
        "# MSE = 1/N * (w*x - y)**2\n",
        "# dj/dw = 1/N * 2x * (w*x - y)\n",
        "def gradient(x, y, y_predicted):\n",
        "    return np.dot(2 * x, y_predicted - y).mean()\n",
        "\n",
        "print(f'prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "##### Training ####\n",
        "learning_rate = 0.01\n",
        "num_of_iterations = 10\n",
        "\n",
        "for epoch in range(num_of_iterations):\n",
        "    # prediction = forward pass\n",
        "    y_pred = forward(x)\n",
        "\n",
        "    # loss\n",
        "    l = loss(y, y_pred)\n",
        "\n",
        "    # gradients\n",
        "    dw = gradient(x, y, y_pred)\n",
        "\n",
        "    # update weights\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print(f'epoch {epoch+1}: weight = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'prediction AFTER training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zXIel3oIkvE",
        "outputId": "0bbf3d73-a960-428c-d5ea-a333d7c75677"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: f(5) = 0.000\n",
            "epoch 1: weight = 1.200, loss = 30.00000000\n",
            "epoch 2: weight = 1.680, loss = 4.79999924\n",
            "epoch 3: weight = 1.872, loss = 0.76800019\n",
            "epoch 4: weight = 1.949, loss = 0.12288000\n",
            "epoch 5: weight = 1.980, loss = 0.01966083\n",
            "epoch 6: weight = 1.992, loss = 0.00314574\n",
            "epoch 7: weight = 1.997, loss = 0.00050331\n",
            "epoch 8: weight = 1.999, loss = 0.00008053\n",
            "epoch 9: weight = 1.999, loss = 0.00001288\n",
            "epoch 10: weight = 2.000, loss = 0.00000206\n",
            "prediction AFTER training: f(5) = 9.999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uuOI1H_7Isdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# f = w * x\n",
        "\n",
        "# f = 2 * x\n",
        "x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "##### model prediction ######\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = Mean Squared Error or MSE\n",
        "def loss(y, y_predicted):\n",
        "    return ((y - y_predicted) ** 2).mean()\n",
        "\n",
        "print(f'prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "##### Training ####\n",
        "learning_rate = 0.01\n",
        "num_of_iterations = 100   #number of steps\n",
        "\n",
        "for epoch in range(num_of_iterations):\n",
        "    # prediction = forward pass\n",
        "    y_pred = forward(x)\n",
        "\n",
        "    # loss\n",
        "    l = loss(y, y_pred)\n",
        "\n",
        "    # gradients = backward pass\n",
        "    l.backward() #calculates the gradients of our loss in respect to w \n",
        "\n",
        "    # update weights\n",
        "    with torch.no_grad():\n",
        "      w -= learning_rate * w.grad\n",
        "  #zero gradients\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:#shows every 1 step, if we change the number after the % it shows after that many steps\n",
        "        print(f'epoch {epoch+1}: weight = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'prediction AFTER training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d387bf0c-ca60-4a96-e13f-c57938ea516f",
        "id": "5H9YEMIhIs2a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: f(5) = 0.000\n",
            "epoch 1: weight = 0.300, loss = 30.00000000\n",
            "epoch 11: weight = 1.665, loss = 1.16278565\n",
            "epoch 21: weight = 1.934, loss = 0.04506890\n",
            "epoch 31: weight = 1.987, loss = 0.00174685\n",
            "epoch 41: weight = 1.997, loss = 0.00006770\n",
            "epoch 51: weight = 1.999, loss = 0.00000262\n",
            "epoch 61: weight = 2.000, loss = 0.00000010\n",
            "epoch 71: weight = 2.000, loss = 0.00000000\n",
            "epoch 81: weight = 2.000, loss = 0.00000000\n",
            "epoch 91: weight = 2.000, loss = 0.00000000\n",
            "prediction AFTER training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial 6: Training Pipeline: Model/Loss/Optimizer"
      ],
      "metadata": {
        "id": "dX_nQKY8KdX_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tF5Ckp3oKlYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}